import tensorflow as tf
import os
import numpy as np
import pandas as pd
from skimage import io
from skimage.transform import resize
from skimage.filters import gaussian

# from deepflash import unet, preproc, utils
from df_resources import unet, preproc, utils, pixelshift37

from skimage.measure import label, regionprops, approximate_polygon
from skimage.draw import polygon, polygon_perimeter
from shapely.geometry import MultiPoint, Polygon
import math


import matplotlib.pyplot as plt



def pixel_shift_3d(np_img, dichroic_dictionary, json_file):
# INPUT: 
#     np_img: numpy image. shape = 3D
#     dichroic_dictionary: dictionary where key=channel number, value=name of dichroic_dictionary
#     json_file: path to the .json file containing the shift values for each dichroic generated by the shift callibration script

# OUTPUT:
#     return: numpy image of shape (n_channels, height, width).  height and width may be different than origional image

    number_of_channels = np_img.shape[0]
    shifted_list = []

    # instantiate PixelShifter class object from pixelshift37
    shift_obj = pixelshift37.PixelShifter(jsonfilepath=json_file)

    # perform shift on each channel
    for ch in range(np_img.shape[0]):
        ch_img = np_img[ch,:,:]
        ch_dichroic = dichroic_dictionary[ch]
        for key in shift_obj.shiftdict.keys():
            if key.split('_')[-1].lower() in ch_dichroic.lower():
                ch_img = shift_obj.shape_images(ch_img)
                shiftval = shift_obj.shiftdict[key]
        img = shift_obj.align_with_shift_matrix(ch_img,shiftval)
        shifted_list.append(img)
    
    # create numpy array where .shape = 3 from list of lists 'shifted_list'
    shifted_img = np.dstack(shifted_list)

    # rearranges shape of numpy array to look more like origional image
    shifted_img = np.moveaxis(shifted_img, -1, 0)
    print("shifted img shape: ", shifted_img.shape)
    
    return(shifted_img)

def correct_shift_upsampling(img):
    if np.issubdtype(img.dtype, np.dtype('uint16')):
        over_values = img > 4095
        img[over_values] = 4095
        return(img)
    elif np.issubdtype(img.dtype, np.dtype('uint8')):
        over_values = img > 255
        img[over_values] = 255
        return(img)

def convert_16_to_8(np_img):
# INPUT:
#     np_img: numpy image.  shape = 2D or 3D

# OUTPUT:
#     return: 8 bit version of origional np_img

    info = np.iinfo(np_img.dtype)
    if np.issubdtype(np_img.dtype, np.dtype('uint16')):
        data = np_img.astype(np.int16)/4095
        # print('ORIGIONAL IMG: ', np.max(np_img))
        # print('CONVERSION: ', np.max(data), " INFO: ", info)
        data = 255 * data
        img8 = data.astype(np.uint8)
        return(img8)
    elif np.issubdtype(np_img.dtype, np.dtype('uint8')):
        return(np_img)



def check_input(df, img_directory='./images'):
    #CHECK IMAGE SHAPE TO CHANNELS GIVEN
    fs = df.file_name.tolist()
    cs = df.ch_order.tolist()
    shs = [io.imread(os.path.join(img_directory, f)).shape for f in fs]
    # for i in range(len(fs)):
        
    print(fs, cs, shs)


def polygons_from_labels(labeled_arr, gene_name):
    df = pd.DataFrame(columns=['cell_n', 'gene_name', 'row_pixels', 'col_pixels'])
    region_props=regionprops(labeled_arr)

    for n, prop in enumerate(region_props):
        p = approximate_polygon(region_props[n].coords, tolerance=2)
        # OR
        # p = region_props[0].coords

        r = p[:,0]
        c = p[:,1]

        # r, c = polygon_perimeter(r,c)
        # new_img[r,c] = 200
        # load_dict = {'cell_n':n, 'row_pixels':r.tolist(), 'col_pixels':c.tolist()}
        # df = df.append(load_dict, ignore_index=True)

        pp=[(x,y) for x,y in zip(r.tolist(), c.tolist())]
        cent=(sum([p[0] for p in pp])/len(pp),sum([p[1] for p in pp])/len(pp))
        pp.sort(key=lambda p: math.atan2(p[1]-cent[1],p[0]-cent[0]))
        # print(pp)
        shapely_poly = Polygon(pp)
        rr, cc = shapely_poly.exterior.coords.xy
        rr = np.asarray(rr, dtype=np.int16)
        cc = np.asarray(cc, dtype=np.int16)
        # print(rr, cc)

        load_dict = {'cell_n':n, 'gene_name':gene_name, 'row_pixels':rr.tolist(), 'col_pixels':cc.tolist()}
        df = df.append(load_dict, ignore_index=True)
    return(df)


def overlap(arr1,arr2,threshold=0.5):
    """
    Values:
    0 = background for arr1
    2 = background for arr2
    1 = signal for both arr1 and arr2
    """
    arr1r = (arr1>threshold)*1
    arr2r = (arr2>threshold)*1
    arr2r[arr2r==0] = 2
    over = np.sum(arr1r==arr2r)
    arr1r_area = np.sum(arr1r==1)
    arr2r_area = np.sum(arr2r==1)
    arr1r_percent = over/arr1r_area
    arr2r_percent = over/arr2r_area
    return(over, arr1r_area, arr1r_percent, arr2r_area, arr2r_percent)



def process_images(df,
                dichroic={0:'dmqb', 1:'dm4', 2:'dm4', 3:'dmqb', 4:'dmqb'},
                jsonfilepath='./df_resources/shiftset.json',
                input_directory='./images',
                output_directory='./processed',
                model_path='./df_resources/full_model.h5',
                minx=2040,
                miny=2040,
                GAUSS=0.1,
                TILE_SHAPE=(540,540),
                PADDING=(184,184),
                SEED=0,
                EL_SIZE=[600, 600], #micrometers
                BATCH_NORM=True,
                LAMBDA=50, #50
                V_BAL=0.1, #0.1
                SIGMA_BAL=10, #10 
                SIGMA_SEP=6 #6
                ):
    
    print(df)
    fs = df.file_name.tolist()
    full_fs = [os.path.join(input_directory, f) for f in fs]

    for i in range(len(fs)):
        out_path=os.path.join(output_directory, fs[i].split('.')[0])
        if not os.path.exists(out_path):
            os.makedirs(out_path)
    
        img=io.imread(full_fs[i])
        ### SLOW: uncomment before use!!!!!!
        # img = pixel_shift_3d(img, dichroic_dictionary=dichroic, json_file=jsonfilepath)
        # img = correct_shift_upsampling(img)
        img = convert_16_to_8(img)

        save_tif_path=os.path.join(out_path, fs[i])
        io.imsave(save_tif_path, img)

        if len(img.shape) == 3:
            image_list = [img[i] for i in range(img.shape[0])]
        else:
            image_list = [img]

        for n in range(len(image_list)):
            if image_list[n].shape != (miny, minx):
                reshaped_img = resize(image_list[n], (miny, minx), anti_aliasing=True)
            if GAUSS is not None:
                reshaped_img = gaussian(reshaped_img, sigma=GAUSS)
            image_list[n] = reshaped_img


        image_list = [np.expand_dims(img, axis=2) for img in image_list]
        img_sizes = [i.shape for i in image_list]

        X_test = np.empty(((0,) + image_list[0].shape))
        X_test = np.append(X_test, np.array(image_list), axis=0)

        data_test = [{'rawdata': img, 'element_size_um': EL_SIZE} for img in X_test]

        test_generator = preproc.TileGenerator(data = data_test,
                                       instancelabels=None,
                                       tile_shape=TILE_SHAPE,
                                       padding=PADDING,
                                       n_classes=2,
                                       border_weight_sigma_px=SIGMA_SEP,
                                       border_weight_factor=LAMBDA,
                                       foreground_background_ratio=V_BAL)

        model = unet.Unet2D(snapshot=model_path, 
                n_channels=1, 
                n_classes=2, 
                n_levels=4,
                batch_norm = BATCH_NORM,
                upsample=False,
                relu_alpha=0.1,
                n_features=64, name='U-Net')

        prediction = model.predict(test_generator)

        print()

        # print(img.shape)
        return(prediction)

